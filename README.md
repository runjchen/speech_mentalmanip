# Detecting Mental Manipulation in Speech via Synthetic Multi-Speaker Dialogue

Status: Under review

Anonymous artifact link: [https://anonymous.4open.science/r/speech_mentalmanip-E798/](https://anonymous.4open.science/r/speech_mentalmanip-E798)



## TL;DR
We extend the text-only mental manipulation benchmark into speech by rendering each dialogue as multi-speaker, voice-consistent TTS. 
This enables 1:1 comparisons between text and audio. Models and humans both struggle more on audio, 
highlighting modality-specific ambiguity and the subjectivity of mental manipulation.

## What’s in this repo?
```
speech_mentalmanip/
├─ README.md                                       # You are here
├─ multi_speaker_TTS_audios_generation_scripts/    # TTS by turn
├─ prediction/                                     # Model Evaluations
```
